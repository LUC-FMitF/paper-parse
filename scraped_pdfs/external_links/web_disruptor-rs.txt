Source URL: https://github.com/nicholassm/disruptor-rs
Final URL: https://github.com/nicholassm/disruptor-rs
================================================================================

# Search code, repositories, users, issues, pull requests...
# Provide feedback
We read every piece of feedback, and take your input very seriously.
Cancel Submit feedback
# Saved searches
## Use saved searches to filter your results more quickly
To see all available qualifiers, see our .
Cancel Create saved search
You signed in with another tab or window. to refresh your session. You signed out in another tab or window. to refresh your session. You switched accounts on another tab or window. to refresh your session. Dismiss alert
You must be signed in to change notification settings
Low latency inter-thread communication library in Rust inspired by the LMAX Disruptor.
### License
You must be signed in to change notification settings
# nicholassm/disruptor-rs
## Folders and files
Name| Name| Last commit message| Last commit date
## Latest commit
## History
## Repository files navigation
# Disruptor
This library is a low latency, inter-thread communication library written in Rust.
It's heavily inspired by the brilliant .
Use it when you want to trade CPU resources for lower latency and higher throughput compared to e.g. Crossbeam or channels.
# Contents
# Getting Started
Add the following to your Cargo.toml file:
disruptor = "3.7.1"
To read details of how to use the library, check out the documentation on .
## Processing Events
There are two ways to process events:
1. Supply a closure to the Disruptor and let it manage the processing thread(s).
2. Use the EventPoller API where you can poll for events (and manage your own threads).
Both have comparable performance so use what fits your use case best. (See also benchmarks.)
## Single and Batch Publication With Managed Threads
Here's a minimal example demonstrating both single and batch publication. Note, batch publication should be used whenever possible for best latency and throughput (see benchmarks below).
// The event on the ring buffer.
// Factory closure for initializing events in the Ring Buffer.
let factory = || { Event { price: 0.0 }};
// Closure for processing events.
let processor = |e: &Event, sequence: Sequence, endofbatch: bool| {
// Your processing logic here.
let mut producer = disruptor::buildsingleproducer(size, factory, BusySpin)
// Publish single events into the Disruptor via the Producer handle.
for i in 0..10 {
e.price = i as f64;
// Publish a batch of events into the Disruptor.
producer.batchpublish(5, |iter| {
for e in iter { // iter is guaranteed to yield 5 events.
e.price = 42.0;
// At this point, the Producer instance goes out of scope and when the
// processor is done handling all events, the Disruptor is dropped
// as well.
## Pinning Threads and Dependencies Between Processors
The library also supports pinning threads on cores to avoid latency induced by context switching. A more advanced usage demonstrating this and with multiple producers and multiple interdependent consumers could look like this:
let factory = || { Event { price: 0.0 }};
// Closure for processing events.
let h1 = |e: &Event, sequence: Sequence, endofbatch: bool| {
// Processing logic here.
let h2 = |e: &Event, sequence: Sequence, endofbatch: bool| {
// Some processing logic here.
let h3 = |e: &Event, sequence: Sequence, endofbatch: bool| {
// More processing logic here.
let mut producer1 = disruptor::buildmultiproducer(64, factory, BusySpin)
// h2 handles events concurrently with h1.
// h3 handles events after h1 and h2.
// Create another producer.
let mut producer2 = producer1.clone();
// Publish into the Disruptor.
s.spawn(move || {
for i in 0..10 {
e.price = i as f64;
s.spawn(move || {
for i in 10..20 {
e.price = i as f64;
// At this point, the Producers instances go out of scope and when the
// processors are done handling all events, the Disruptor is dropped
// as well.
## Processors with State
If you need to store some state in the processor thread which is neither Send nor Sync, e.g. a Rc >, then you can create a closure for initializing that state and pass it along with the processing closure when you build the Disruptor. The Disruptor will then pass a mutable reference to your state on each event. As an example:
use std::{cell::RefCell, rc::Rc};
#[derive(Default)]
let factory = || { Event { price: 0.0 }};
let initialstate = || { State::default() };
// Closure for processing events with state.
let processor = |s: &mut State, e: &Event, : Sequence, : bool| {
// Mutate your custom state:
s.data.borrowmut() += 1;
let mut producer = disruptor::buildsingleproducer(size, factory, BusySpin)
for i in 0..10 {
e.price = i as f64;
## Event Polling
An alternative to storing state in the processor is to use the Event Poller API:
// The event on the ring buffer.
// Factory closure for initializing events in the Ring Buffer.
let factory = || Event { price: 0.0 };
let builder = disruptor::buildsingleproducer(size, factory, BusySpin);
let (mut poller, builder) = builder.eventpoller();
let mut producer = builder.build();
// Publish single events into the Disruptor via the Producer handle.
for i in 0..10 {
e.price = i as f64;
match poller.poll() {
// &mut events implements ExactSizeIterator so events can be
// batch processed and handled with e.g. a for loop.
for event in &mut events {
// Process events here.
},// When the guard (here named events) goes out of scope,
// it signals to the Disruptor that reading is done.
Err(Polling::NoEvents) => {
// Do other work or poll again.
Err(Polling::Shutdown) => {
// Disruptor is shut down so no more events will be published.
# Features
Single Producer Single Consumer (SPSC).
Single Producer Multi Consumer (SPMC) with consumer interdependencies.
Multi Producer Single Consumer (MPSC).
Multi Producer Multi Consumer (MPMC) with consumer interdependencies.
Busy-spin wait strategies.
Batch publication of events.
Batch consumption of events.
Event Poller API.
Thread affinity can be set for the event processor thread(s).
Set thread name of each event processor thread.
# Patterns
## A Disruptor with Different Event Types
Let's assume you have multiple different types of producers that each publish distinct events. It could be an exchange where you receive e.g. client logins, logouts, orders, etc.
You can model this by using an enum as event type:
Order{userid: i32, price: f64, quantity: i32},
Then you can differentiate on different event types in your processor:
let factory = || { Event::Heartbeat };
let processor = |e: &Event, sequence: Sequence, endofbatch: bool| {
Event::Login{id} => { / Register client login. / }
Event::Logout{id} => { / Register client logout. / }
Event::Order{userid, price, quantity} => { / Add an order to the CLOB. / }
Event::Heartbeat => { / Heartbeat from somewhere. / }
let mut producer = disruptor::buildmultiproducer(64, factory, BusySpin)
let mut loginproducer = producer.clone();
let mut logoutproducer = producer.clone();
let mut orderproducer = producer.clone();
loginproducer.publish( |e| e = Event::Login{id: 1});
orderproducer.publish( |e| e = Event::Order{userid: 1, price: 100.0, quantity: 10});
logoutproducer.publish(|e| e = Event::Logout{id: 1});
producer.publish( |e| e = Event::Heartbeat);
## Splitting Workload Across Processors
Let's assume you have a high ingress rate of events and you need to split the work across multiple processors to cope with the load. You can do that by assigning an id to each processor and then only process events with a sequence number that modulo the number of processors equal the id. Here, for simplicity, we split it across two processors:
let processor0 = |e: &Event, sequence: Sequence, endofbatch: bool| {
if sequence % 2 == 0 {
// Process event.
let processor1 = |e: &Event, sequence: Sequence, endofbatch: bool| {
if sequence % 2 == 1 {
// Process event.
This scheme ensures each event is processed once.
# Design Choices
Everything in the library is about low-latency and this heavily influences all choices made in this library. As an example, you cannot allocate an event and move that into the ringbuffer. Instead, events are allocated on startup to ensure they are co-located in memory to increase cache coherency. However, you can still allocate e.g. a struct and move ownership to a field in the event on the Ringbuffer.
There's also no use of dynamic dispatch - everything is monomorphed.
# Correctness
This library needs to use Unsafe to achieve low latency. Although the absence of bugs or data races cannot be guaranteed without formal proofs, these approaches have been used to eliminate logic errors:
Minimal usage of Unsafe blocks.
High test coverage.
All tests are run on Miri in CI/CD.
Verification in TLA+ (see the verification/ folder).
Furthermore, the code is carefully handcrafted by me with only a little bit of AI intellisense (which was carefully reviewed).
# Performance
The SPSC and MPSC Disruptor variants have been benchmarked and compared to Crossbeam. See the code in the benches/spsc.rs and benches/mpsc.rs files.
The results below of the SPSC benchmark are gathered from running the benchmarks on a 2016 Macbook Pro running a 2,6 GHz Quad-Core Intel Core i7. So on a modern Intel Xeon the numbers should be even better. Furthermore, it's not possible to isolate cores on Mac and pin threads which would produce even more stable results. This is future work.
If you have any suggestions to improving the benchmarks, please feel free to open an issue.
To provide a somewhat realistic benchmark not only burst of different sizes are considered but also variable pauses between bursts: 0 ms, 1 ms and 10 ms.
The latencies below are the mean latency per element with 95% confidence interval (standard criterion settings). Capturing all latencies and calculating misc. percentiles (and in particular the max latency) is future work. However, I expect the below measurements to be representative for the actual performance you can achieve in a real application.
## No Pause Between Bursts
Burst Size | Crossbeam | Disruptor | Improvement
1 | 65 ns | 32 ns | 51%
10 | 68 ns | 9 ns | 87%
100 | 29 ns | 8 ns | 72%
Burst Size | Crossbeam | Disruptor | Improvement
1 | 15.2M / s | 31.7M / s | 109%
10 | 14.5M / s | 117.3M / s | 709%
100 | 34.3M / s | 119.7M / s | 249%
## 1 ms Pause Between Bursts
Burst Size | Crossbeam | Disruptor | Improvement
1 | 63 ns | 33 ns | 48%
10 | 67 ns | 8 ns | 88%
100 | 30 ns | 9 ns | 70%
Burst Size | Crossbeam | Disruptor | Improvement
1 | 15.9M / s | 30.7M / s | 93%
10 | 14.9M / s | 117.7M / s | 690%
100 | 33.8M / s | 105.0M / s | 211%
## 10 ms Pause Between Bursts
Burst Size | Crossbeam | Disruptor | Improvement
1 | 51 ns | 32 ns | 37%
10 | 67 ns | 9 ns | 87%
100 | 30 ns | 10 ns | 67%
Burst Size | Crossbeam | Disruptor | Improvement
1 | 19.5M / s | 31.6M / s | 62%
10 | 14.9M / s | 114.5M / s | 668%
100 | 33.6M / s | 105.0M / s | 213%
## Conclusion
There's clearly a difference between the Disruptor and the Crossbeam libs. However, this is not because the Crossbeam library is not a great piece of software. It is. The Disruptor trades CPU and memory resources for lower latency and higher throughput and that is why it's able to achieve these results. The Disruptor also excels if you can publish batches of events as demonstrated in the benchmarks with bursts of 10 and 100 events.
Both libraries greatly improves as the burst size goes up but the Disruptor's performance is more resilient to the pauses between bursts which is one of the design goals.
# Related Work
There are multiple other Rust projects that mimic the LMAX Disruptor library:
A key feature that this library supports is multiple producers from different threads that neither of the above libraries support (at the time of writing).
# Contributions
You are welcome to create a Pull-Request or open an issue with suggestions for improvements.
Changes are accepted solely at my discretion and I will focus on whether the changes are a good fit for the purpose and design of this crate.
# Roadmap
Empty! All the items have been implemented.
## About
Low latency inter-thread communication library in Rust inspired by the LMAX Disruptor.
### Resources
### License
### Uh oh!
There was an error while loading. .
### Stars
### Watchers
### Forks
No packages published
### Uh oh!
There was an error while loading. .
### Uh oh!
There was an error while loading. .
## Languages
(C) 2026 GitHub, Inc.
* Do not share my personal information
You canâ€™t perform that action at this time.