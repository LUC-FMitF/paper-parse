Source: qrl.pdf
================================================================================

Paxos Quorum Leases: Fast Reads Without Sacrificing Writes
IulianMoraru,DavidG.Andersen,MichaelKaminsky
CarnegieMellonUniversityandIntelLabs
Abstract asthe“stableleader”andisresponsiblefororchestratingall
operations. Absentfailures,Multi-Paxosenablesoperations
Thispaperdescribesquorumleases,anewtechniquethatal- tocommitinasingleroundtripfromtheleadertoamajority
lowsPaxos-basedsystemstoperformreadswithhighthrough- ofreplicas. InaMulti-Paxosenvironment,themostcommon
putandlowlatency. Quorumleasesdonotsacrificeconsis- readleaseoptimizationistograntthestableleaderareadlease
tencyandhaveonlyasmallimpactonsystemavailabilityand onallobjectscomprisingthestate—files,key-valuepairsor
writelatency. Quorumleasesallowamajorityofreplicasto relationaldatabaserecords,dependingontheapplication. As
performstronglyconsistentlocalreads,whichsubstantially aresult,readscanbehandledwithasingleround-triptothe
reducesreadlatencyatthosereplicas(e.g.,bytwoordersof leader,andwritesincurnoadditionalslowdown,comparedto
magnitudeinwide-areascenarios). Previoustechniquesfor aPaxossystemthatdoesnotuseleases.
performinglocalreadsinPaxossystemseither(a)sacrifice Other systems, such as Google’s Megastore [3], instead
consistency; (b) allow only one replica to read locally; or grant a read lease to all nodes. This decision aggressively
(c)decreasethe availabilityofthesystemand increasethe optimizesforreadsattheexpenseofwritelatency: allreads
latencyofallupdatesbyrequiringallreplicastobenotified canbehandledlocallyatareplicawithnointer-replicatraffic
synchronously. We describe the design of quorum leases whatsoever,butallwritesnowinvolveatleastoneround-trip
andevaluatetheirbenefitscomparedtopreviousapproaches toeveryreplica(insteadofjustthenearestmajority).
through an implementation running in five geo-distributed Whileoptimizingthereadperformanceisclearlyimportant
AmazonEC2datacenters. (forexample,theread-to-writeratioinGoogle’sadvertising
backendF1is340:1[8]),thefactthatMegastore’ssuccessor
systemSpanner[8]hasabandonedtheMegastorelease(in
1 Introduction
favoroftheleaderleaseandsnapshotreads)suggeststhatfew
applicationsarewillingtosacrificetheperformanceofwrites
Paxos[18]anditsnumerousvariantsforstatemachinerepli-
inexchange.
cation have become increasingly important for large-scale
Inthispaper,wearguethatthereisanoverlookedalterna-
Internetservices. Theyextendtospanmassivedatacenters,
tivethatisamorenaturalfittothestructureofPaxos:quorum
geo-replicatewithinandacrosscontinents,andhandletens
leases. Inthismodel,aleaseforeachobjectinthesystem
of billions of operations each day [8]. Many Paxos-based
couldbegrantedtodifferentsubsetsofnodes. Thesizeand
systemsimproveperformancebyusingsomeformofread
composition of these subsets is selected either based upon
leases, inwhichoneorseveralreplicascansatisfyreadre-
howfrequentlyeachreplicareadstheobjectsinquestion(for
questslocallywithouthavingtocommitanoperationusing
bestreadperformance)orbasedupontheirproximitytothe
therelativelymoreexpensivePaxosprotocol. Thisoptimiza-
leader(toimprovereadperformancewithoutslowingwrite
tionobviouslyimprovesreadthroughputandlatency,butalso
performance). Aparticularlysuitablesizeforthissubsetis
improveswriteperformancebyreducingthetotalnumberof
that of a Paxos quorum: we claim that quorum leases are
operationsthatmustbehandledbythePaxosreplicas.
a “natural” fit to Paxos because writes in Paxos must, by
Avarietyofapproachestoreadleaseshavebeenusedin
definition,synchronouslycontactatleastasimplemajority
practicalsystems. MostPaxos-basedsystemsusetheMulti-
ofnodesanyway. Thus,theleaserevocationandthePaxos
Paxosoptimization,inwhichonenodeistemporarilyselected
messagescanbecombined,oftenresultinginnoadditional
overheadordelaysforhandlingaleasedobject.
Permissiontomakedigitalorhardcopiesofpartorallofthisworkfor
personalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot Despitetheintuitivenessofthisapproach,implementing
madeordistributedforprofitorcommercialadvantageandthatcopiesbear quorum leases is nontrivial. Compared to approaches in
thisnoticeandthefullcitationonthefirstpage.Copyrightsforthird-party
whichthesetofnodeswiththeleaseisfixed—eitherasingle
componentsofthisworkmustbehonored. Forallotheruses,contactthe
Owner/Author. masterorallreplicas—animplementationofquorumleases
mustbeabletoconsistentlydeterminewhichobjectsbelong
CopyrightisheldbytheOwner/Author(s). towhichleasequorum,automaticallydetermineappropriate
SOCC’14,Nov03-052014,Seattle,WA,USA.
leasedurations,andefficientlyrefreshtheleasesinawaythat
ACM978-1-4503-3252-1/14/11.
http://dx.doi.org/10.1145/2670979.2671001 balancesoverhead,ahighhitrateonleasedobjects,andrapid
1
lease expiration in the event of a node or network failure. Client
Solvingtheseproblemsandevaluatingtheresultingbenefits Request(cmd)
istheprimaryobjectiveofthiswork.
Replica 1
Ourresults(Section5)suggestthatquorumleasespresent (leader)
an extremely attractive middle ground for practical Paxos- Accept(cmd) Committed(cmd)
AcceptOK
Replica 2
basedsystems: runningtheYCSBbenchmarkworkloadona
geo-distributeddeploymentoffive-replicaMulti-Paxoswith
quorumleases,over80%ofreadsarehandledlocally,withno Replica 3
wide-areatraffic,ateachreplica,andover70%ofwriteshave
the smallest client-observed latency attainable in a Multi- Figure 1: Steady state interaction in Multi-Paxos. The
Paxos system, for the given geographic configuration. In asynchronous messages are represented as dashed ar-
contrast,asingleleaderleasesystemachieves100%ofmin- rows.
imallatencywrites,butonly20%ofreadsarelocal(those
performedbythestableMulti-Paxosleader).
thecommandthatthereplyingreplicabelievesmayhaveal-
ready been chosen in this instance (in which case the new
2 Overview leadermustusethatcommandinsteadofthenewlyproposed
one),andalsoconstitutesapromisenottoacknowledgeolder
WebeginwithashortoverviewofthePaxosprotocol,and messagesfrompreviousleaders. Ifthenewleaderreceives
thenwepresenttheintuitionofapplyingquorumleasesto atleast N/2 +1acknowledgementsforPreparemessages,
b c
Paxos. it will proceed to propose its command by sending Accept
messagestoamajorityofpeers;ifthesemessagesarealsoac-
2.1 PaxosOverview knowledgedbyamajority,theleadercommitsthecommand
locally,andthenasynchronouslynotifiesallitspeersandthe
ThePaxosprotocol[19]isusedtoimplementstatemachine client.
replicationbymakingasetofpossiblyfaultydistributedrepli- Becausethiscanonicalmodeofoperationrequiresatleast
casexecutethesamecommandsinthesameorder. Because tworoundsofcommunication(tworoundtrips)tocommita
eachreplicabehaveslikeastatemachine,allnon-faultyrepli- command—andpossiblymoreinthecaseofduelingleaders—
cas will transition through the same sequence of states as thewidelyused“Multi-Paxos”optimization[19]designates
a result. To be able to make progress, fewer than half the astableleader replica(i.e.,thedistinguishedproposer). A
replicascanbefaulty—ifN isthetotalnumberofreplicas, replicabecomesthestableleaderbyrunningthepreparephase
atleast N/2 +1mustbeworkingcorrectly. Paxoshandles foralarge(possiblyinfinite)numberofinstancesatthesame
b c
only non-Byzantine failures: replicas may crash or fail to time,takingownershipofallofthem. Insteadystate,clients
respondindefinitely,buttheycannotrespondinwaysthatdo sendcommandsonlytothestableleader,whichdirectlypro-
notconformtotheprotocol. posesthemintheinstancesitalreadyowns(withoutrunning
TheoriginalandmostgeneralspecificationofPaxosuses thepreparephasefirst). Whenanon-leaderreplicasuspects
processorswithdifferentroles: leaders,acceptorsandlearn- thattheleaderhasfailed,ittriestobecomethenewleaderby
ers. Inpractice,theserolesarecollapsed,andareplicaplays takingownershipofalltheinstancesitbelieveshavenotyet
multiple roles at the same time. Because this corresponds beenfinalized.
topracticaldeployments,wepresentourdesignintermsof Figure 1 presents a time diagram depicting the message
replicaswithidenticalcapabilities. exchangesinaMulti-Paxossystem,insteadystate.
TheexecutionofareplicatedstatemachinethatusesPaxos
proceeds as a series of independent instances, where the
2.2 QuorumLeases: Intuition
outcome1ofeachPaxosinstanceistheagreementonwhich
commandmustbeexecutedbyeveryreplicaataparticular Recallthataleaseisatime-limitedpromisefromoneprocess
position in the linear sequence of commands. The voting toanothertonotmodifyanobjectduringtheleaseduration.
processforoneinstancemayhappenconcurrentlywithvoting Leases are often coupled with a revocation mechanism: If
processesforotherinstances,butdoesnotinterferewiththem. theleasegrantorwishestomodifytheobjectbeforethelease
Uponreceivingacommandrequestfromaclient,areplica has expired, it must contact each lease holder and receive
firsttriestobecometheleaderofaninstancecorresponding confirmationthattheholderwillstopusingitslocalcopyof
toacommandpositionitbelieveshasnotbeenused. Itdoes theobject,asshowninFigure2.
sobysendingPreparemessagestoatleastamajorityofrepli- Quorumleasesintertwinetheideaofleasingwiththenat-
cas(possiblyincludingitself). AreplytoaPreparecontains ural set of nodes that must be contacted for a Paxos write,
bundlingthePaxoswriteoperationwiththeleaserevocation.
1ByFLP[10],itisimpossibletoguaranteetermination,althoughunder
InPaxos,areplicacancommitacommandonlyafterama-
realisticconditions, usingtimeoutsandretransmittingmessagesensures
terminationwithhighprobability. jorityquorum—possiblyincludingitself—hasacknowledged
2
Leasing with time expiration
Grant
lease R1 R3
Local Writes
Local Reads R4
Not Allowed
Possible
Lease
R2
Holders
Lease expires
Grantors (any size)
Local Writes Local Reads (Majority)
Possible Not Allowed
R5
Leasing with early revocation
L N o o c t a A l l W low rit e e d s R
G
E
r
V
a
O
nt
K
l
E
ease
Local Reads
F
ca
ig
s
u
(
r
R
e
1
3
,
:
R
A
2
n
,
e
a
x
n
a
d
m
R
p
5
le
)
l
h
e
a
a
v
se
e
i
g
n
r
w
an
h
t
i
e
c
d
h
l
a
ea
m
se
a
s
jo
t
r
o
ity
tw
o
o
fr
le
e
a
p
s
li
e
-
Possible
holders(R4andR5).
OK
Local Reads
Local Writes Not Allowed
Possible 3 Design
Figure2: Leasingwithandwithoutrevocation. We begin by describing the assumptions about the Paxos
systemsthatusequorumleases.Wethendescribeourquorum
leasesdesigngoalsandmotivateourdesignchoices.
thecommand. Asisapparentfromtherevocationexample
3.1 Assumptions
inFigure2,ifthewritequorumincludesallnodesthathold
leasesontheobjecttobemodified,thenreceivingacknowl- Communication between the nodes is asynchronous: mes-
edgementsfromthewritequorumalsomeansthatthelease sages may be lost or delayed indefinitely. Replicas do not
hasbeenproperlyrevokedatallreplicas. synchronizeclocks, buttheirclockratesareassumedtobe
similar,suchthatamodestguardtimecanaccountforclock
Of course, this simple design has several complications: driftoverashortinterval. Failuresarenon-Byzantine: repli-
(1) if any member of the quorum becomes unavailable, no cascancrashorfailtorespondindefinitely,buttheywillnot
commandcanbecommitteduntiltheleaseexpires;and(2) takeactionsthatdonotconformtotheprotocol.
replicasoutsidethequorumcannotperformlocalreads. We assume that the replicated state consists of multiple
objectsthatcanbeupdatedandreadseparately. Clientssub-
Wesolvethefirstproblembycarefullychoosingthelease
mit operations that specify which objects will be updated,
durationrelativetotheround-triptimebetweenthereplicas.
andqueriesforreadingobjectvalues. Multipleupdatesand
Aquorumisnotifiedsynchronouslyonlyforasetamountof
queriescanbebatchedinthesamecommand.
time,afterwhichnoneofitsmemberscanrelyontheirstate
beingupdatedsynchronouslyanymore. Ifaquorummember
crashes,thesystemwillbeunavailableonlyuntilthelease 3.2 DesignGoals
expires.
AquorumleaseprovidesasubsetofPaxosreplicastheguar-
anteethattheywillbenotifiedsynchronouslyofanyupdateto
Toreducetheopportunitycostofnotleasingtothefullset
aparticularsetofobjectsbeforethoseupdatesarecommitted
ofnodes,wegrantleasesonaper-objectbasis,whereeach
byanyreplica.Thus,letRbethesetofallreplicasinaPaxos
leasemighthaveadifferentsetofnodesholdingit. Inthis
group, andletO bethesetofallobjectsreplicatedbythis
way,whilenotallnodescanreadlocally,thenodesgenerating
Paxosgroup. Aquorumleaseisapair(Q,O),whereQ R
themostreadtrafficforeachobjectcandoso. Thisdesignis
✓
andO O. WecallQtheleasequorumforthislease,and
particularlyappropriatewhenthepopularityofeachobject
✓
Othesetofgrantedobjects. Everyreplicar Qisalease
differs substantially across replicas—such as might be the
2
holder.
case,e.g.,inthepopularityofusersacrossageo-distributed
Unlike a Paxos quorum, which must include a majority
socialnetwork.
ofreplicas,aleasequorumcanbeofanysize—e.g.,itcan
Inconclusion,quorumleasestakeadvantageoftheexisting containfewerthanhalfthereplicas.
communicationpatternsinPaxostoallowreplicastoperform A lease becomes active after a majority of replicas (i.e.,
localreads,withoutsubstantiallydecreasingtheavailabilityof at least N/2 +1 replicas, where N = R ) have granted
b c | |
thesystem,andwithoutsignificantlyincreasingwritelatency. theleasetoatleastoneleaseholder. Anexampleofsucha
3
lease is shown in Figure 3, where a majority have granted anygivenmomentaleaseconfiguration,andweusePaxos
readleasestotwonodesintheset. Areplicaggrantsalease toachieveconsensusonleaseconfigurationchanges. Con-
(Q,O)toareplicar Qbymakingapromise: ceptually,thereisaseparate,independentPaxos-replicated
2
statemachinefortheconfigurationstate;inourimplementa-
1. tonotifyrsynchronouslybeforecommittinganyupdate tion,theconfigurationPaxosinstantiationrunsonthesame
toanyobjectinOthatgproposes(i.e.,gmustnotcom- nodesasthemainPaxosinstantiation. Becausereplicaclocks
mituntilitreceivesamessagefromrinresponsetoits arenotsynchronized,wemustestablishtimingdependencies
notification),AND whengrantingandrefreshingleases. Wedothisthroughsep-
2. toacknowledgeAcceptandPreparemessages2 forup- aratecommunication,independentoftheleaseconfiguration
dates to objects in O only with the condition that the changeprotocol(seebelow).
proposermustalsonotifyrsynchronouslybeforecom- Becauseanunresponsiveleaseholderwillpreventupdates
mittingtheseupdates. to the leased objects until the lease expires, it is useful for
leases to be granted for short periods of time, which are
Toenforcethefirstconditionwithoutextracommunication,
refreshedbeforetheyexpire.
gwillincluderinanyPaxosquorumofacceptorsbeforecom-
mittingaPaxoscommandthatitproposes(i.e.,forwhichit
3.3 DesignOverview
istheleader). Toenforcethesecondcondition,everyreplica
must attach enough information to its replies to the Paxos Althoughwebelievethatquorumleasesapplytoanyvariant
AcceptandPreparemessagesfromaproposerthatthepro- of Paxos, we focus for clarity on the most popular: Multi-
posercandeterminewhichreplicastheresponderhasgranted Paxos.
leasesto;theproposerusesthisinformationtosynchronously Whileusingquorumleases,thereplicasofaPaxossystem
notifytheleaseholdersbeforecommitting.WeexplaininSec- communicate using two categories of messages: (1) The
tion3.4howtoimplementthisexchangeefficientlybyadding normal Paxos messages for choosing commands; and (2)
onlyashortleaseidentifiertoeachmessage. Grantorsmake Lease management messages. We separate these in both
promisesusingaprotocolseparatefromPaxos,describedin design and implementation to make it easier to reuse the
Section3.5 leases with other Paxos variants, and to modify the lease
Topreventunboundedperiodsofunavailability,apromise managementprotocol.
isvalidforonlyasetamountoftime,afterwhichitexpires. Leasemanagementconsistsoftwomessagesub-types:(2a)
In a correct implementation, a promise must expire at the Paxosmessagesforagreeingonleaseconfigurationchanges—
lease holder before expiring at the grantor. When a lease whatarethequorumsandwhatisthesetofobjectIDsgranted
holderhasfewerthan N/2 validpromisesfromdifferent toeachquorum;and(2b)messagesforgrantingandrefresh-
b c
replicas(theholderitselfcountsasanimplicitgrantor),the ingleases.
leaseissaidtobeinactiveforthatholder. Toavoidadependencyonexternalclocksynchronization,
Thismechanismachievesthefollowing: whiletheleaseis wesetleasetimersbaseduponthecausalorderingofmessag-
activeataleaseholder,thatleaseholdercanassesswhether ingeventsusingalightweightpeer-to-peerprotocoldescribed
anupdatetoanyoftheleasedobjectsisongoing(i.e.,inthe indetailinSection3.5.Thisprotocolefficientlycombinesthe
processofbeingcommitted),andifnot,theleaseholdercan computationofleasetimersandthegrantingandrefreshing
readthemostup-to-datevalueofthatobjectfromitslocal ofleases.
store. Separatingleaseconfigurationandgrantingconveyssev-
Aquorumleasecanbegrantedtoanysubsetofreplicas, eral advantages. First, it means that the granting protocol
ofanysize. However,becauseupdatesinPaxosmustbeac- could be improved independently ofthe rest of the system
ceptedsynchronouslybyamajorityofreplicasevenwhennot to take advantage of, e.g., hardware clock synchronization
usingleases,itisadvantageousforbothlatencyandavailabil- orstrongerassumptionsaboutdelaysbaseduponknowledge
itytomakeleasequorumsbesimplemajorities( N/2 +1 ofthephysicalconnectionsbetweenmachines. Importantly,
b c
outofthetotalofN replicas). Forreducedwritelatency,itis thesimplicityoftheleasegrantingprotocolalsomakesshort
alsousefulthateveryleasequorumincludethecurrentdistin- leaseintervalsfeasible,whichhasimportantbenefitsforavail-
guishedproposer(i.e.,thecurrentstableleader,ifthePaxos ability. The lease renewal messages are short and can be
variantusedreliesonastableleader—suchas,forexample, piggybackedonexistingtraffic,astheyrefertothecurrent
Multi-Paxos). leaseconfigurationthroughashortconfigurationID,instead
Different Paxos replicas may need to read different sets ofneedingtoexplicitlydescribequorumsandgrantedobjects
of objects at different times. We therefore wish to be able astheleaseconfigurationmessagesmust.
to update both the set of leased objects, and the lease quo-
rums. Wecallthetotalityofquorumleasesagreeduponat
3.4 LeaseConfigurations
2The condition for acknowledging Prepare messages applies only to
Aleaseconfigurationdescribesthequorumcompositionand
instanceswherethegrantorhasalreadyacceptedanupdateforanobjectin
O. thesetofgrantedobjectsforallthequorumleasesinaPaxos
4
systematagiventime. T1 T3 T5 t_lease
A lease configuration is built incrementally from a se- t_lease
t_guard
quence of lease configuration changes. Replicas agree on R1
lease configuration changes through Paxos—they partici- guard promise T R 5 1 ' + s t p _ r l o e m as is e e : T t 3 _l e + a t s _ e g : u R a 1 rd 's +
pate in Paxos instances that are separate from the normal guard_ACK promise_ACK expires at R1 if promise
promise_ACK expires at R1 if
command-choosing instances. The result is a sequence of no promise_ACK
R2
leaseconfigurationchangesthatall(non-faulty)replicasagree
t_lease T4 + t_lease:
upon. Aleaseconfigurationisthensimplyreferredtobythe t_guard R1's promise
T2 T4 expires at R2
instancenumberofthelatestchange.
Ourbasicimplementationofquorumleasesstrivestoas- Figure4:Whenclocksarenotsynchronized,theleaseac-
sign leases such that: (a) the lease is granted to a simple tivatingprocedureusesacknowledgementstosafelyman-
majority of nodes; and (b) the number of locally-satisfied age lease intervals. In this diagram, the lease duration
read operations is maximized; and (c) the total number of is t lease. A grantor (R1) will only send a promise if its
leasesbeingmanagedismodest. 3 guard is acknowledged by the holder (R2). The grantor
Itaccomplishesthisbyhavingreplicastrackthefrequency can thus bound the promise duration even if the holder
ofreadsandperiodicallysendthisinformationtothecurrent doesnotreplytothepromise.
Multi-Paxos leader.4 The leader determines the next lease
configurationsuchthateachobjectisgrantedtothemajority
quorumthatconsistsofthestableleaderandthe N/2 ad- replicainthesystem(thusbecomingagrantor). Thepromise
b c includesthenumberofthemostrecentleaseconfiguration
ditionalreplicasthathavereadtheobjectmostoften;itthen
thatthegrantorisawareof,theleaseduration,andatimes-
proposesthisnewconfiguration—asetof(quorum,objectID
tamp. A receiver (i.e., a lease holder) rejects promises for
list)pairs—inoneofthespecialPaxosinstances. Because
leaseconfigurationsolderthanthenewestoneitisawareof.
itisalreadyguaranteedtoseeallwritesbyvirtueofbeing
A lease represents a time during which the grantor will
theMulti-Paxosleader,thestableleaderisgrantedadefault
not modify an object without contacting the holder, which
leasethatcoverseveryobjectnotinanotherlease,andisalso
givestheholderpermissiontoreadthatobjectlocally. For
includedineveryleasequorum.
safety,thegrantor’s“willnotmodify”windowoftimemust
Therearemanypossiblewaystomaintainreadstatistics.
be inclusive of the holder’s “can read locally” window of
Inourcurrentimplementation,whenareplicareceivesaread
time. Forhighavailability,thesetimesshouldbeasshortas
request that it cannot service locally, it forwards it to the
possible,sothatafailedholdercanonlyblockwritesfora
stableMulti-Paxosleader. Theleadercountsthenumberof
shortperiodoftime. Thesegoalsareaccomplishedbythe
forwardedreadrequestsforeachobject-replicapair. Ifthe
leaseestablishingandrenewalprotocoldescribedinFigures4
numberofreadsfromagivenreplicaislargerthanthenumber
and 5.
ofreadsfromanotherreplicapreviouslyincludedasalease
Beforesendingapromise,thegrantorsendstheholdera
holderfortheobject,theleaderwillincludethenewreplica
guard message, which the holder must acknowledge. The
asaleaseholderinthenextleaseconfigurationupdate.
guardspecifiesatimedurationt .Thesubsequentpromise
Lease configuration changes happen sufficiently infre- guard
containsaleasedurationt . Importantly, thepromiseis
quentlythattheycanbewrittentoastablelogwithoutaffect- lease
onlyvalidifreceivedbytheholderbeforet hasexpired.
ingtheperformanceofthesystem. guard
Thisensuresthateveniftheholderdoesnotrespondtothe
promise,thegrantorknowsthattheholderwillnotbelieveit
3.5 ActivatingLeases hasaleasesubsequenttot +t secondsafteritreceived
guard lease
theguardACK.
Replicasagreeonaleaseconfigurationasdescribedinthe
Aholderstartsaleasetimerassoonasitreceivesapromise.
previoussection, butthequorumleasesthatconstitutethis
Thepromiseexpiresafteritsspecifiedleaseduration(t )
configurationbecomeactiveonlyafterbeinggrantedasex- lease
haspassed. Aleaseholdercanconsidertheleaseactivewhile
plainedinthissection.
there are at least N/2 promises received from different
The lease configuration covers all leases granted on all b c
peersthathavenotyetexpired.
objects (which may involve many different sets of holder
When renewing active leases, there is no need to send
replicas),andsoreplicasaffirmthisconfigurationinanall-
theguardanymore. Themostrecentacknowledgedpromise
to-allmanner. Everyreplicasendsapromisetoeveryother
plays the role of the guard: when sending a new promise,
3Manyotheroptimizationgoalsarebothpossibleandreasonable;explor- thegrantorindicatesthatitmustbereceivedwithinatime
ingthemmoredeeplyisaninterestingavenueoffuturework. t 0 +t guard fromthemostrecentreceivedacknowledgment(the
4Uncompressed,thisadditionaltrafficamountstoatmost100KB/sec grantorindicateswhichACKthiswas),wheret isthetime
0
perreplica(basedonthemaximumreadratesachievedbyourprototype).
elapsedatthegrantorsincereceivingthisacknowledgment.
However,itispossibletomaintainapproximatereadstatisticswithoutany
Therefore, the grantor will be able to safely relinquish its
additionaltraffic,byhavingtheMulti-Paxosleadercounthowmanytimesa
replicathatisnotaleaseholderforwardsreadrequestsforeachobject. promiseaftert guard +t lease secondsfromsendingtherenewal.
5
Whenagrantorbecomesawarethatanewleaseconfigura- replicagrantor . Becausegrantor acceptsW,itmustbethe
R R
tionhasbeenagreeduponwhileitsmostrecentpromisesare casethatW’sproposerwilllearnthatthereisanactivelease
stillvalid,itcantakeoneoftwoapproaches: (1)thegrantor whengrantor repliestoitsAccept. Therefore,W’sproposer
R
canletitscurrentpromisesexpire,andthensendpromises willknowthatitmustnotifyreader beforecommittingW
R
forthenewconfiguration;or(2)thegrantorcanimmediately (evenifthisproposerhasnotmadeanypromisesitself),and
sendpromisesforthecurrentconfiguration,butwhileboth reader must executeW before executing any further read,
R
setsofpromisesarevalid,itmustabidebytheleaserulesof includingR. Inconclusion,RwillobserveW.
boththepreviousandthecurrentconfiguration.5 Forsimplic-
Case 2: reader R acquired the lease after W began. This
ity,ourcurrentimplementationtakesthefirstapproach.
casehasthreesub-cases: (1)Ifthereexistsanacceptorthatis
Theleaseestablishingandrenewinglogicisdescribedin
partofW’sPaxosquorumandthatgrantsreader thelease
R
pseudocodeinFigure5.
before acceptingW, then this scenario reduces to the pre-
vious case. (2) If reader itself acceptsW before its lease
R
3.6 EnsuringStrongConsistency becomesactive,itmustexecuteW beforeR. (3)Thereexists
anacceptorgrantor thatfirstacceptsW andthenmakesa
R
Paxos and Multi-Paxos provide strong consistency: opera-
promisethatreader takesintoaccountwhenactivatingits
R
tionsarestrictlyserializable(theyarebothserializableandthe
lease. Because promises contain the index of the most re-
temporalorderofnon-overlappingoperationsisrespected).
centacceptedPaxosinstanceatthegrantor(thereforeatleast
In this section we show that quorum leases maintain this
asrecentasW’sinstanceatgrantor ),reader knowsthatit
R R
consistencyguarantee.
mustwaitforcommitsforallinstancesuptoandincluding
Write-only and composite read-write operations will be
W’sinstancebeforereplyingtoanyread(includingR). These
committedthroughthenormalPaxosprotocolandexecuted
threesub-casesareexhaustive.
atomically. Theywillthusbestrictlyserializable. Everysim-
In conclusion, a Paxos system that implements quorum
pleorcompositeread-onlyoperationwilleitherbeserviced
readleasesensuresstrictserializability.
atomicallybyareplicathatholdsleasesforalltheobjectsin
question,orwillbecommittedthroughnormalPaxosifno
suchreplicaexists. Thus,thesystemensuresserializability. 3.7 RecoveringafteraReplicaFailure
Toensurestrict serializability,noticethatitisnecessary
The failure of a lease holder will prevent the system from
andsufficienttoshowthatgivenaread-writeorwrite-only
committingupdatestoanyobjectforwhichtheleaseholder
operationW and a read-only operation R, where the write
hasaleaseuntilenoughofthepromisesmadetoitexpire.The
set ofW intersects with the read set of R, then the system
systemcanresumecommittingonceamajorityofreplicasare
observestheirtemporalorder.Thatistosay(1)ifRcompletes
nolongerboundtonotifythefaultyreplicasynchronously. In
beforeW beginsatanyreplica,RdoesnotobserveW;and(2)
practice,thetimeforwhichitisblockedisontheorderofa
ifW iscommittedatanyreplicabeforeRisreceivedbyany
fewtotenseconds,dependingontheround-triptimebetween
replica,RobservesW. IfRiscommittedthroughPaxos,this
thereplicas,asweanalyzemorecarefullyinSection3.8.
istruebyvirtueofthePaxosprotocolguarantees. Wemust
A grantor suspects that a replica may have failed if that
showthatthepropertyalsoholdswhenRisservicedlocally
replicastopsreplyingtoitspromisesorheartbeatmessages
bysomereplica.
(common in many Paxos implementations). After a grace
IfRcompletesbeforeW begins,thepropertyholdstrivially:
period,thegrantorwillstoptryingtorenewitspromises,and
Rcannotreturnaversionthatdoesnotyetexistanywhere.
itwilllettheonesmadesofarexpire. Inthemeantime,the
WearethereforeleftwiththecasewhereW wascommitted
grantorwillcontacttheMulti-Paxosleaderrequestingaspe-
beforeRwasreceived.
cialleaseconfigurationupdatethatspecifiesthatthereplica
ThereplicathatservicesRlocally(wewillcallitreader )
R suspectedoffailureshouldbeexcludedfromallquorumsit
canonlydosoifithasaleasefortheobjectsthatRrefersto.
waspartof. Replicasthatswitchtothisnewconfiguration
Wemustthereforebeinoneofthefollowingsituations:
nolongerneedtosynchronouslynotifythepossibly-failed
Case1:reader RacquiredtheleasebeforeW began. Inthis replicaofupdates,andthesystemcansafelyresumeusing
case,reader ’sleasewasactivethroughoutW’sPaxoscommit leases.
R
process. Becausetheleaseisactive,bythecausalordering A replica that rejoins the replica set after a failure must
ofgrantorsandholdersstartingtheirleasetimers,itmustbe waitfort (Section3.8)secondsbeforeitcanacceptand/or
wait
thecasethatatleast N/2 +1replicas(possiblyincluding proposeanycommandstoensurethatallofitspromiseshave
b c
reader R )havegrantedreader R thelease,andtheirpromises expired.
arestillactive(i.e.,binding). Thequorumofreplicasthatac-
ceptedW willintersectthisquorumofgrantorsinatleastone
3.8 LeaseTimeandFailuresAnalysis
5Forexample,ifanobjecthasbeengrantedtoadifferentquorum,the
Inthissectionweanalyzetherelationshipbetweentheinter-
grantormustensurethatitnotifiessynchronouslyeveryreplicaintheunion
ofthetwoquorumsbeforecommittinganupdatetotheobject. replicaRTTs,theleaseduration,andthemaximumwindow
6
Establishingleases Renewingleases
EveryreplicaRbecomesagrantor: EveryreplicaRthatisagrantor:
1: sendGuard(guard duration)toeveryotherreplica 14: foreveryotherreplicaH do
2: foreveryGuardACK fromanyreplicaH do 15: set
3: set grant timer R [H] lease duration+guard duration
grant timer R [H] guard duration+lease duration 16: sett 0 thetimesincethemostrecentACKfromH
4: sendPromise(lease duration)toH 17: setseq ACK thesequencenumberofmostrecent
5: foreveryPromiseReplyfromanyreplicaH do ACKfromH
6: ifreplyreceivedbeforegrant timer R [H]expiredthen 18: sendPromise(lease duration,t 0 ,seq ACK )toH
7: setgrant timer R [H] lease duration 19: foreveryPromiseReplyfromanyreplicaH do
AnyreplicaH,onreceivingaGuard(guard duration) 20: setgrant timer R [H] min(grant timer R [H],
lease duration)
fromareplicaR:
8: setguard timer H [R] guard duration AnyreplicaH,onreceivingaPromise(lease duration,t 0,
9: replywithaGuardACK seq ACK )fromareplicaR:
10: waitforaPromise(lease duration)fromR 20: ifPromisereceivedbeforetimet 0 +guard duration
11: ifPromisereceivedbeforeguard timer H [R]expires sincesendingACKwithsequenceseq ACK then
then 21: setlease timer H [R] lease time
12: setlease timer H [R] lease duration 22: replywithPromiseReplytoR
13: replywithPromiseReplytoR
AleaseholderH canconsidertheleaseactiveifatleast N/2 promisesfromdifferentreplicashaveyettoexpire
{ b c
(whereN isthetotalnumberofreplicas).
}
Figure5: Establishingandrenewingquorumleases.
ofwriteunavailabilityafteraleaseholdercrashesorbecomes immediately, but they cannot update any objects leased by
temporarilyunavailable. the crashed node until they can be certain the crashed (or
Theguardperiodt (Section3.5)mustbelargerthan partitioned)nodewillnotreaditsobjectslocally. Weterm
guard
themaximumround-triptimebetweenanytworeplicas;oth- this timet wait , and it is calculated as follows: in the worst
erwise,thesoon-to-beleaseholderwillrejectthesubsequent case,thegrantorsentapromiserightbeforethegraceperiod
promise when it arrives. The lease duration t , on the expired, and therefore, by the renewal logic, it must wait
lease
otherhand,canbearbitrarilysmallbecausegrantorscansend for t wait =t guard +t lease before it can consider this promise
theleaserenewaltraffic“blind”—thatis, withoutknowing expired.
whetherornotitspreviousleaserenewalshadbeenreceived Themaximumperiodofwriteunavailabilitycausedbya
successfully. However,forrenewalstobeconsistentlysuc- failedleaseholderisthereforet grace +t wait =t grace +t guard +
cessfulevenwhenmessagesarelostandretransmitted,the t lease . Forwide-areasetups,thiswillbeontheorderofsec-
leasedurationshouldbehigherthanoneRTT,andrenewals onds(approximately9secondsfor2secondsleaseandgrant
shouldbetriggeredatleastoneRTTbeforeexpiration(the periodsanda5secondgraceperiod.)
largertheleaseperiodandthehighertherenewalfrequency, Aftert expires,butbeforet expires,thelivereplicas
grace wait
themorelikelyitisthatpacketlosswillnotaffectreadper- willinitiatealeaseconfigurationchange(Section3.7)sothat
formance). theycanresumeusingleasesaftert expires.
wait
Agrantorwillstopissuingnewleasesonceitbelievesa IfthePaxosleaderfails,theunavailabilitytimewillbethe
replica is down, as indicated by a failure to reply to some maximumofthetimetoelectaleaderandt grace +t wait .
previousmessage. Suchamessagelosscanonlybedetected
after(atleast)oneround-triptimebetweenthegrantorand
3.9 Multi-objectOperationsandBatching
grantee. Inpractice,agrantorwilllikelywaitsomeadditional
timebeforebelievingareplicafailed. Wetermthistotaltime, Withquorumleases,differentobjectsmaybegrantedtodif-
fromtheinstantthatareplicacouldhavefailedtothetimeits ferentquorums. Therefore, multi-objectupdateoperations
grantorstopsissuingleaserenewals,the“graceperiod”t grace . mustbesynchronouslyacknowledgedbyasuper-quorum—
Attheendofthegraceperiod,thegrantorswillconclude theunionofallquorumsthatleaseanobjectupdatedbythe
thatthenodeinquestionhascrashed. Thegrantorscanex- multi-objectoperation. Ifsuchoperationsarefrequent,this
clude the crashed node from the lease configuration state mayaffecttheperformanceandtheavailabilityofthesystem.
7
Apossiblesolutionistotrackthoseobjectsthatarefrequently JP CA OR VA IRL
updatedtogetherandensuretheyarealwaysgrantedtothe Japan 0.4 120 120 180 270
samequorum. California 0.4 20 85 150
Oregon 0.4 75 170
Asimilarproblemariseswithbatching. Batchingincreases
Virginia 0.4 92
thethroughputofPaxossystemsbygroupingmultiplecon-
Ireland 0.4
currentoperationsinasinglePaxoscommand. Iftheseopera-
tionsupdateobjectsleasedbydifferentquorums,thebatch
Table1: Approximateround-triptimesbetweendatacen-
must be accepted synchronously by the union of all corre-
tersinmilliseconds.
sponding quorums. To avoid this, replicas must separate
objects granted to different quorums into different batches
beforeproposingthem. Underheavyrequestload(usually leasesthantoquorumorMegastore-leases.6
thesituationthatwarrantsbatchingtosustainahighthrough-
put)therewillusuallybeenoughoperationsofeachtypefor
batchingtostillbeeffective. 5 Evaluation
Werunourimplementationsofquorumleases,classicleader
leasesandMegastore-typeleases,bothinasingleAmazon
EC2cluster,andinageo-distributedsetting:fiveMulti-Paxos
4 Implementation
replicasruninfiveAmazonEC2datacenters,locatedinVir-
ginia,NorthernCalifornia,Oregon,IrelandandJapan. Ten
We implemented quorum leases, classic leader leases and clientsareco-located(i.e.,inthesamedatacenter)witheach
Megastore-typeleaseswithinanexistingMulti-Paxossystem replica. ReplicasandclientsrunonlargeAmazonEC2in-
writteninGo(ourcodeisavailableopensource[23]). Be- stances:two64-bitvirtualcoreswithtwoEC2ComputeUnits
causeourmainfocusisonthemessageandround-triptime eachand7.5GBofmemory. ThetypicalRTTinanEC2clus-
reductions(orincreases)duetoleasinginthewidearea,we teris0.4ms. Theround-triptimesbetweendatacentersare
usuallyrunthesystematthroughputlevelswheretheimple- summarizedinTable1.
mentation details are not the bottleneck. This reduces the
importanceofaspecificchoiceofPaxosframework.
5.1 TheWorkload
WritingPaxoscodethatuseswall-clocktimeisstandard
practice—becauseofthenecessityofusingtimeouts,andalso Inourexperiments, weuseMulti-Paxostoreplicateakey-
becausetheleaderleaseisacommonoptimization[4,6,8]. valuestore. Lackingaccessto,e.g.,usertracesfromamajor
Quorumleasesaremorecomplexthanleaderleases,butthe Internetservice,weusetheYCSB[7]key-valueworkloadto
bulk of the implementation deals with aspects that are not benchmarkit.7 EveryclientinoursystemproposesPutand
criticalforsafety,onlyforperformance. Thechangestothe GetoperationswithkeysdrawnfromeitheraZipfdistribution
corePaxoscodearerelativelystraightforward. (withanexponentof0.99—thedefaultYCSBimplementa-
tionofaZipfgenerator)orauniformdistribution. Forthe
Because a major focus for all leasing strategies is to re-
Zipf distribution, the most popular items differ across dat-
ducelatencyinthewidearea,weimplementedaspartofour
acenters: the sequence of keys ordered by popularity is a
baselinealatencyoptimizationdescribedbyCastro [5]. This
different random permutation for each datacenter. We ran
optimizationreducesthecommitlatencyperceivedbyclients
experimentsfortwoworkloadratiosofPutstoGets—1:1and
thatareco-locatedwithareplicaotherthantheMulti-Paxos
1:9—witheachclientchoosingtheoperationtypeatrandom.
stableleader,byhavingotherreplicastransmittheirAccep-
TheskewedZipfdistributionistheidealworkloadforquo-
tRepliestoboththestableleaderandtothereplicanearthe
rumleasesbecauseclientsindifferentdatacenterswillmostly
client. Thus,inthecommoncase,theclientdoesnotneedto
accessdifferentobjects. Theuniformlydistributedworkload,
waittheadditionaltimeforamessagetocomebackfromthe
ontheotherhand,istheworstcasescenarioforquorumleases
stableleader,whichreducescommittimefromfourone-way
delaystothree.
6Withoutleases,thenear-clientreplicawillbeabletocommitassoonas
Weimplementedthisoptimizationbecause,whileitdoes itreceives N/2 AcceptReplies,or N/2 1AcceptRepliesandanAccept
b c b c 
notappeartobecommonlydeployed,itisastraightforward fromtheleader(becauseitisimplicitthattheleadermusthaveaccepted
too).Withleases,thecommitconditionismorestrict:thereplicaclosestto
algorithmictweakthatreducescommitlatencyandtherefore
theclientcancommitanoperationafterreceivingAcceptorAcceptReplies
more accurately represents the state of the art of the write messagesfromallthereplicasthatholdtheleasefortheobjectsupdated
latencythatcanbeachievedbyaPaxos-basedsystem. This bytheoperations(inadditiontothepreviousconditionthatatleast N/2
b c
replicasintotalsignalthattheyhaveaccepted).
optimizationbenefitsallthreeimplementations(leaderleases,
7Foreaseofintegrationwithourimplementation,weimplementeda
Megastore-typeleases,andquorumleases),butinsomecases
customworkloadgeneratorthatusesthesamedistributionsasYCSBviaa
confers slightly more of an advantage to traditional leader directtranslationoftheYCSBcodeintoGo.
8
becauseanobjectisequallylikelytobeaccessedbyreplicas Fastlocalreads
thatholdaleaseforitasbyreplicasthatdonot. Japan 81%
California 95%
Oregon 89%
5.2 Latency
Virginia 89%
Weranthisworkloadinthewidearea,foronehundredthou- Ireland 81%
sandkeys,withfiftysimultaneousclients,tenateachofthe
fivelocations.8 Eachclientsendstenthousandrequeststothe Table 2: Percentages of fast local reads (smaller than
co-locatedreplica,inaclosedloop,andmeasuresthelatency 10ms)forwide-areaquorumleaseswith10%writesand
(therearethus500,000requestsintotal). Forwrites,clients 90%reads,Zipf-distributed.
arenotifiedassoonastheoperationhasbeencommitted,so
wedonotwaitforittobeexecuted.Thisissufficienttoensure
TheMegastore-typeleaseallowseveryreplicatoreadany
strictserializability: afterreceivingthecommitnotification,
objectlocally,butrequiresproposerstonotifyallotherrepli-
theclientcansafelyassumethatanysubsequentoperations
cassynchronouslybeforecommittingawrite. Typical(95%)
(proposedbyitselforotherclients)willbegloballyordered
readlatenciesareunder10ms—onetotwoordersofmag-
afteritswrite. Aread,ontheotherhand,isexecutedbefore
nitudefasterthanwhencommunicationwitharemotedata-
notifying the client, so that the read value can be returned
centerisrequired. Asmallpercentageofreadrequestsare
withthenotification.
delayed by concurrent writes to the same objects: when a
Inallexperiments,theMulti-PaxosleaderisinCalifornia.
writeisongoing,areplicamustdelayinterferingreadsuntil
Basedontheround-triptimesshowninTable1,Californiais
itcanbesurethatthewritewillbecommitted(i.e.,typically
thedatacenterclosesttothecenter.
untilithasreceivedacommitnotification). Thepriceofthis
Wesettheleaseparametersasfollows: theleaseduration
near-optimalreadperformanceisincreasedwritelatency,by
was2seconds,everygrantorrenewedthecurrentleaseafter
morethan100msinmostcasescomparedtotheotherleasing
500 milliseconds, and the lease configuration was updated
schemes. Eachreplicamustwaitforthereplicafarthestaway
every10seconds.
toacknowledgeanupdatebeforecommittingitandnotifying
Thecumulativedistributionoflatencies,separateforreads
theclient. Furthermore,thisschemeincursmoreriskofun-
andwrites,ispresentedinFigure6forallthreeleasestrate-
availabilityforwrites: anyunresponsivereplicawillprevent
gies: quorumleases,single-leaderlease,andMegastore-type
allupdatesfromprogressinguntilthereplica’sleaseexpires.
leases. ForquorumleaseswerunbothZipf-distributedand
Quorumleasesareacompromisebetweenthetwoprevious
uniformlydistributedworkloads. Fortheskewedworkload,
schemes. Over 80% of reads at every site are performed
weletthesystemadaptfor5000requestsfromeachclient
locally. Over 70% of updates have the minimum latency
beforewebeginmeasuringlatencies. Theratioofreadsto
achievablebyageo-distributedMulti-Paxossystem,matching
writes is 1:1. This high frequency of writes increases the
thatprovidedbythesingleleaderlease,and2 to3 faster
chancethatreadswillhavetowaitforconcurrentwritesto ⇥ ⇥
(i.e. 100to200millisecondslowerlatency)thanwriteswith
thesameobjecttofinishbeforetheycanexecute,soitcon-
the Megastore approach. Because all replicas are likely to
stitutesadisadvantageforquorumleases. Forcompleteness,
bepartofatleastonequorumlease,anyreplicafailurewill
wealsopresentasummaryofquorumleaseresultsforthe9:1
causesomeunavailabilityforwrites. However,thisdoesnot
readtowriteratioinTable2(theothertwoleasingstrategies
affectallwrites(asitwouldforMegastore-typeleases),but
benefitonlymarginallyfromthisworkloadchange,theirread
onlywritestotheobjectsgrantedtothefailedreplica.
latenciesbeingalreadyverylowandveryhigh,respectively).
The worst scenario for quorum leases is that when the
Thesingleleaderleaseprovidesthebestwriteperformance
workloadisuniformlydistributed(alsopresentedinFigure6).
becausetheleadercanalwayschoosethefastestquorumfor
Forthatexperiment,wesetthequorumleasesstatically,based
committingawrite. Theleaderisthesoleownerofthelease,
ongeographicalproximity: oneleaseincludesthereplicasin
sonoparticularotherreplicamustbenotifiedsynchronously
California,JapanandOregon,theotherincludesCalifornia,
whenanupdateoccurs. Thefastestquorumalwaysincludes
Virginia and Ireland. Each leases half the key space. As
thereplicaclosesttotheclient,totakefulladvantageofthe
expected,approximatelyhalftherequestateachlocationwill
optimizationdescribedinSection4. Thislowwritelatency,
thereforehavetheminimumlatency,whiletheotherhalfwill
however, comes at a cost: only the leader can read locally.
exhibittheworstcaselatency.
Thus,thesingleleaderleasesuffersmeanreadlatencyatleast
two orders of magnitude larger than that of the competing
strategies. 5.3 RecoveringfromaReplicaFailure
8Alargerkeyspacewouldbeadvantageousforquorumleases,makingit Figure7depictstheevolutionofwritelatencyovertimein
lesslikelyforakeytobeaccessedbyanon-lease-holder.Largernumbers
anexperimentwhereanon-leaderreplicafails. Clientsco-
ofconcurrentclientswouldincreaseonlytailreadlatency,correspondingto
located with the Paxos leader generate write requests at a
thoseraresituationswhenareadisdelayedbyasimultaneouswritetothe
samekey. steadyrateandmeasurethecommitlatency. Approximately
9
100
80
60
40
20
0
1 10 100 1000
sdaeR
fo
egatnecreP
California
100
QL
QL-uniform 80
LL
ML
60
40
20
0
10 100 200 300 1000
Read Latency [ms]
setirW
fo
egatnecreP
California
QL
QL-uniform
LL
ML
Write Latency [ms]
100
80
60
40
20
0
1 10 100 1000
sdaeR
fo
egatnecreP
Japan
100
QL
QL-uniform 80
LL
ML
60
40
20
0
10 100 200 300 1000
Read Latency [ms]
setirW
fo
egatnecreP
Japan
QL
QL-uniform
LL
ML
Write Latency [ms]
100
80
60
40
20
0
1 10 100 1000
sdaeR
fo
egatnecreP
Oregon
100
QL
QL-uniform 80
LL
ML
60
40
20
0
10 100 200 300 1000
Read Latency [ms]
setirW
fo
egatnecreP
Oregon
QL
QL-uniform
LL
ML
Write Latency [ms]
100
80
60
40
20
0
1 10 100 1000
sdaeR
fo
egatnecreP
Virginia
100
QL
QL-uniform 80
LL
ML
60
40
20
0
10 100 200 300 1000
Read Latency [ms]
setirW
fo
egatnecreP
Virginia
QL
QL-uniform
LL
ML
Write Latency [ms]
100
80
60
40
20
0
1 10 100 1000
sdaeR
fo
egatnecreP
Ireland
100
QL
QL-uniform 80
LL
ML
60
40
20
0
10 100 200 300 1000
Read Latency [ms]
setirW
fo
egatnecreP
Ireland
QL
QL-uniform
LL
ML
Write Latency [ms]
Figure6:CDFsofclient-observedlatencyforeachsite,withallthreeleasetechniques:quorumlease(QL),singleleader
lease(LL),andMegastore-typelease(ML).QL-uniformcorrespondstoquorumleasesforauniformly-distributedwork-
load. Theread-to-writeratiointheseexperimentswas1:1. TheMulti-PaxosleaderisalwayslocatedinCalifornia. Note
thelogscaleontheXaxis.
10
10000
1000
100
10
0 10000 20000 30000 40000 50000
]sm[
ycnetaL
Command issue time [ms]
Figure 7: Latency of write requests over time. Ten sec-
ondsintotheexperiment,anon-leaderreplicafails.
700000
600000
500000
400000
300000
200000
100000
0
Leader-lease Quorum-lease Megastore-lease
]ces/spo[
tuphguorhT
weusebatchingtocommitwrites(theleaderbatchesupto
5000updatesatatime),thedifferenceinmessagingpatterns
betweenthethreeleaseimplementationsislessimportant,so
theirwritethroughputsareapproximatelythesame. Quorum
leaseshavea10%lowerwritethroughputbecausewemust
separatetheupdatesintoper-quorumbatches(i.e.,onlyup-
datesleasedbythesamequorumarebatchedtogether). In
thelocalcluster,Megastoreleasesachievehigherthroughput,
atthecostofsufferingmoreimpactuponnodefailure: all
leases will be stalled when any replica becomes available,
whereaswithaquorumlease, anunresponsivereplicawill
stallonlyupdatesfortheobjectsithasleased. Ingeneral,our
resultssuggestthatthedifferencesbetweenMegastore-type
leasesandquorumleasesarelessimportantinalocalclus-
584K 617K terthantheyareinthewidearea,ifthroughputisthemain
Reads consideration.
Writes
Uniformly
distributed reads
206K 5.5 Discussion
149K 132K 115K 125K
Theseexperimentsconsideredsingle-objectoperationsexclu-
sively. Formulti-objectoperations, ifthesameobjectsare
usuallyaccessedtogether,thentheywillbeleasedtogether,
andthereforethecorrespondingreadandwritelatencieswill
besimilartothosereportedhere. Ontheotherhand,thewrite
Figure 8: Local-area read and write throughput for dif-
latency of multi-object writes that target objects leased by
ferent leasing strategies. The “Uniformly-distributed
differentquorumswillapproachthatoftheMegastoreleases.
reads” for quorum leases corresponds to the situation
Ifsuchoperationsarecommon,andmulti-objectreadsthat
whenclientsdonotknowwhichreplicascanreadlocally
spanquorumsarealsocommon,theMegastoreleasemaybe
which objects. Error bars represent 95% confidence in-
moresuitable.
tervals.
6 Related Work
tensecondsintotheexperiment,anon-leaderreplicathatis
aleaseholderfails. Aftera5secondgraceperiod,andthen
Time-basedleaseshavebeenintroducedasawayofimprov-
aftertheexpirationofthelastleaserenewalsentbeforethe
ingthelatencyofreadswhilemaintainingstrongdatacon-
endofthegraceperiod(i.e.,the2secondleasedurationplus
sistency in distributed systems [2, 4, 11, 13, 25]. Quorum
the 2 second guard—as explained Section 3.8) the system
leasespreservethisgoalinthecontextofPaxosreplicated
recoversavailabilityforwrites.
statemachines.
Previous systems have used leases to improve the read
5.4 ThroughputinaCluster performance of Paxos systems in two ways. First, Chan-
draetal.[6]proposedthePaxosleaderlease(alsousedin
While our focus is on wide-area replication, we evaluate Chubby[4]andSpanner[8]),whichgivestheMulti-Paxos
thethroughputofthethreeleasingstrategiesinalocal-area leadertheabilitytoperformstrongly-consistentreadslocally,
clusteraswell. Figure8comparesthemaximumreadand foraspecifiedtimeinterval. Second,Megastore[3],awide-
writethroughputsachievedwithallthreeleasingstrategies. areadeploymentofPaxos,effectivelygrantseveryreplicain
Forquorumleases,wepresentresultsfortwosituations: (1) thesystemaleaseforeveryobject:awriteinMegastoremust
differentobjectsarepopularatdifferentreplicas—i.e.,when synchronously send aninvalidatemessage to every replica
tryingtoreadacertainobject,allclientsknowwhichreplica thathasnotacceptedthewrite—sothattheremotereplica
has a lease for that object; and (2) clients are oblivious of knowsitscopyoftheobject(entitygroup,inMegastoretermi-
leaseassignment,anddirecttheirreadsuniformlyatrandom nology)isstale. Asshowninourevaluation,theleaderlease
acrossallreplicas. Intheseexperiments,therequestswere andtheMegastoreleaseareatoppositeextremesofthedesign
generatedopen-loopbyoneclientforeachreplica—thiswas spectrumforleasesinPaxos: leaderleasesallowforoptimal
sufficienttosaturatethesystem. Multi-Paxoswritelatency,whileMegastoreleasessacrifice
Megastoreleaseshavethebestreadthroughput,narrowly write latency for optimal read latency at every replica. By
surpassingquorumleaseswhenclientsareawareofleaseas- contrast,quorumleasesallowforamorefine-grainedexplo-
signments,and4 higherthansingle-leaderleases. Because rationofthedesignspace:leasescanbegrantedtoanysubset
⇥
11
ofreplicasandtheyrefertoonlyaspecifiedportionofthe problem: allowingsingle-replicaconsistentreads, anoper-
replicatedstate,sothatdifferentreplicascanholddifferent ation generally incompatible with Byzantine fault tolerant
leasesatthesametime. Forageo-distributedreplicatedstate systems.
machinethatobserveslocalityinthepopularityofitsrepli- Per-client leases are also used in systems such as
cated objects, quorum leases can approximate the benefits Chubby [4] and Farsite [2] to allow clients to operate on
ofbothpreviousapproachessimultaneously. Thiscomesat cachedsub-partsofthereplicateddata(i.e.,cachedfiles).
theexpenseofsimplicity,becausequorumleasesaremore Quorum leases are superficially similar to the notion of
complextomanage. preferredquorums[1,9].Thekeydistinctionisthataquorum
Spanner [8] is a leader-leased, Paxos-based system that leaseconstitutesarequirementtosynchronouslyupdateeach
usesTrueTime—accurateclocksynchronizationclocksyn- lease holder, while preferred quorums are a performance
chronizationthatrequiresspecialhardware—toimprovegeo- optimization. InQ/U[1],clientstrytocommunicatewiththe
distributedreadperformance. Itdoessointwoways: first,it samepreferredquorumofreplicaseverytimetheywantto
improvesthemanagementofleaderleases,bytakingadvan- accessaparticularobject,toincreasethechancethatthose
tageoftheirsynchronizedclocks. Second,itcanletremote replicasareup-to-datewithallthelatestversions. Quorum
replicasreadlocallybyissuingsnapshotreads,attimestamps leases,bycontrast,guaranteethatreplicasintheleaseholder
specified by clients. Like a quorum lease, a snapshot read subsetareup-to-date,soclientscanreadfromanyonereplica
executeslocally. Unlikeaquorumlease,however,asnapshot inthatsubsetandnotanentirequorum. HQreplication[9]
readmaynotbeup-to-datewithrespecttoupdatesalready makesonlyaquorumofreplicasexecutethefullprotocolin
committedatotherreplicas. failure-freesituationstoreducethemessagingoverhead.
Othersystems,suchasZooKeeper[14]andMDCC[17],
allowfastlocalreads,butmakenofreshnessguarantees(i.e., 7 Conclusion
theresultsmaybestale).
Previous systems have used Paxos as a mechanism for Thispaperpresentedthedesignandimplementationofquo-
grantingleases:FaTLease[15]andPaxosLease[24]arerepli- rumleasesforPaxos. Byexploitingtheexistingmessaging
cated state machines that grant leases to individual clients. requirements for Paxos operations, quorum leases provide
They use Paxos to ensure the fault tolerance of the lease- a natural, and therefore efficient, mechanism for allowing
management system, and take advantage of the perishable localreadsinaPaxos-replicatedsystemwithoutsubstantially
propertyofleasestoavoidloggingPaxosstatetodisk. By increasingthedelayforwriteoperationstocommit. Oureval-
contrast,quorumleasesaregrantedtothereplicasthemselves uationongeo-distributedreplicasinAmazonEC2datacenters
(nottheclients)basedonthepopularityofreplicatedobjects, showsthattheseleasesworkwellinpractice:Morenodescan
andtheycanbegrantedtomultipleentities(replicas)atthe performreadslocallythanwithsimplemaster-onlyleases,but
sametimeinsteadofjustone. Furthermore,unlikeFaTLease thewritelatencyincreasesonlymodestlyandonlydoesso
and PaxosLease, quorum leases specify how leases are en- fortypicallyfewerthan10-20%ofoperations. Wetherefore
forced,notjusthowtheyaregranted. believethatquorumleasesareanexcellentgeneral-purpose
Although we have presented quorum leases only in the leasingmechanismforPaxos-basedsystems.
context of Multi-Paxos, the most widely used variant of Acknowledgements: WethankourshepherdJinyangLi,the
Paxos,webelievetheycanalsobeappliedtootherPaxosvari- anonymousSoCCreviewers,GarthGibson,MiguelCastro,
ants[20,21,22],aswellassystemsusingsimilarmajority- andGregGanger. ThisresearchwasfundedinpartbyIntel
consensus replication protocols [14]. Leaderless Paxos viatheIntelScienceandTechnologyCenterforCloudCom-
variants, in particular, like Mencius [21] and Egalitarian puting(ISTC-CC),bytheNationalScienceFoundationunder
Paxos[22]areagoodfitforquorumleasesbecausetheydo awardCCF-0964474,andbyagiftfromGoogle.
notrequireasinglereplicatobepartofeverywritequorum—
this gives more flexibility in choosing lease quorums, and
benefitsbothwritelatencyandavailability,especiallywith References
EgalitarianPaxos,whichoptimizesforwide-areaPaxoscom-
[1] M.Abd-El-Malek,G.R.Ganger,G.R.Goodson,M.K.Re-
mitlatency.
iter, andJ.J.Wylie. Fault-scalablebyzantinefault-tolerant
The use of leases in improving the performance of dis-
services.InProc.20thACMSymposiumonOperatingSystems
tributedprotocolsisnotrestrictedtoPaxos. Zzyzx[12]isa
Principles(SOSP),pages59–74,Brighton,UK,Oct.2005.
Byzantinefaulttolerantsystemthatgivesclientsexclusive
[2] A.Adya,W.J.Bolosky,M.Castro,G.Cermak,R.Chaiken,
lockstoobjects. Itdoessoinordertoprecludecompeting
J.R.Douceur,Jon,J.Howell,J.R.Lorch,M.Theimer,andR.P.
clientrequests,andthustoreducethecommoncommitpath Wattenhofer. FARSITE:Federated,Available,andReliable
byonemessagedelay(halfaroundtrip)whencomparedto StorageforanIncompletelyTrustedEnvironment. InProc.
Zyzzyva[16].ComparedtothemechanisminZzyzx,quorum 5thUSENIXOSDI,pages1–14,Boston,MA,Dec.2002.
leasesaregrantedtothereplicasthemselves,somultiple(or [3] J.Baker,C.Bond,J.C.Corbett,J.Furman,A.Khorlin,J.Lar-
all)clientscanbenefitfromeachlease,andsolveadifferent son,J.-M.Leon,Y.Li,A.Lloyd,andV.Yushprakh.Megastore:
12
Providingscalable,highlyavailablestorageforinteractiveser- MDCC: Multi-data center consistency. In Proc. 8th ACM
vices. InProc.oftheConferenceonInnovativeDatasystem EuropeanConferenceonComputerSystems(EuroSys),Apr.
Research(CIDR),pages223–234,2011. 2013.
[4] M.Burrows. TheChubbylockserviceforloosely-coupled [18] L.Lamport. Thepart-timeparliament. ACMTransactionson
distributedsystems. InProc.7thUSENIXOSDI,Seattle,WA, ComputerSystems,16(2):133–169,1998. ISSN0734-2071.
Nov.2006. [19] L.Lamport. Paxosmadesimple. ACMSIGACTNews,32(4),
[5] M.CastroandB.Liskov. Practicalbyzantinefaulttolerance Dec.2001.
andproactiverecovery. ACMTransactionsonComputerSys- [20] L. Lamport. Fast Paxos. http://research.
tems,20(4):398–461,Nov.2002. microsoft.com/apps/pubs/default.aspx?
[6] T.D.Chandra,R.Griesemer,andJ.Redstone.Paxosmadelive: id=64624,2006.
anengineeringperspective. InProc.26thACMSymposium [21] Y.Mao,F.P.Junqueira,andK.Marzullo. Mencius:building
on Principles of Distributed Computing, PODC ’07, pages efficient replicated state machines for WANs. In Proc. 8th
398–407,NewYork,NY,USA,2007.ACM. USENIXOSDI,pages369–384,SanDiego,CA,Dec.2008.
[7] B. Cooper, A. Silberstein, E. Tam, R. Ramakrishnan, and [22] I.Moraru,D.G.Andersen,andM.Kaminsky. Thereismore
R.Sears. BenchmarkingcloudservingsystemswithYCSB. consensusinegalitarianparliaments. InProc.24thACMSym-
InProc.1stACMSymposiumonCloudComputing(SOCC), posiumonOperatingSystemsPrinciples(SOSP),Farmington,
Indianapolis,IN,June2010. PA,Nov.2013.
[8] J.C.Corbett,J.Dean,M.Epstein,A.Fikes,C.Frost,J.Furman, [23] I. Moraru, D. G. Andersen, and M. Kaminsky. Quorum
S.Ghemawat,A.Gubarev,C.Heiser,P.Hochschild,W.Hsieh, leasescodebase. https://github.com/efficient/
S.Kanthak,E.Kogan,H.Li,A.Lloyd,S.Melnik,D.Mwaura, qlease,Oct.2014.
D.Nagle,S.Quinlan,R.Rao,L.Rolig,Y.Saito,M.Szymaniak,
[24] M.Trencseni,A.Gazso,andH.Reinhardt. PaxosLease:Disk-
C.Taylor, R.Wang, andD.Woodford. Spanner: Google’s
lessPaxosforLeases. http://arxiv.org/pdf/1209.
globally-distributeddatabase. InProc.10thUSENIXOSDI.
4187.pdf,2012.
USENIX,2012.
[25] J.Yin,L.Alvisi,M.Dahlin,andC.Lin. Volumeleasesfor
[9] J.Cowling,D.Myers,B.Liskov,R.Rodrigues,andL.Shrira.
consistencyinlarge-scalesystems.IEEETrans.onKnowl.and
Hqreplication:Ahybridquorumprotocolforbyzantinefault
DataEng.,11(4):563–576,July1999.
tolerance.InProc.7thUSENIXOSDI,pages177–190,Seattle,
WA,Nov.2006.
[10] M.J.Fischer,N.A.Lynch,andM.S.Paterson. Impossibility
ofdistributedconsensuswithonefaultyprocess. J.ACM,32
(2):374–382,Apr.1985. ISSN0004-5411.
[11] C.GrayandD.Cheriton. Leases: anefficientfault-tolerant
mechanismfordistributedfilecacheconsistency. InProceed-
ings of the twelfth ACM symposium on Operating systems
principles,SOSP’89,pages202–210,NewYork,NY,USA,
1989.ACM.
[12] J.Hendricks, S.Sinnamohideen, G.Ganger, andM.Reiter.
Zzyzx:Scalablefaulttolerancethroughbyzantinelocking. In
DependableSystemsandNetworks(DSN),2010IEEE/IFIP
InternationalConferenceon,pages363–372,June2010.
[13] J. Howard, M. Kazar, S. Menees, D. Nichols, M. Satya-
narayanan,R.Sidebotham,andM.West. ScaleandPerfor-
manceinaDistributedFileSystem. ACMTransactionson
ComputerSystems,6(1),Feb.1988.
[14] P.Hunt,M.Konar,F.P.Junqueira,andB.Reed. ZooKeeper:
wait-free coordination for internet-scale systems. In Proc.
USENIXATC,USENIXATC’10,Berkeley,CA,USA,2010.
USENIXAssociation.
[15] F.Hupfeld,B.Kolbeck,J.Stender,M.Ho¨gqvist,T.Cortes,
J.Marti,andJ.Malo. Fatlease: scalablefault-tolerantlease
negotiationwithpaxos. InProceedingsofthe17thinterna-
tionalsymposiumonHighperformancedistributedcomputing,
HPDC’08,pages1–10,2008.
[16] R. Kotla, L. Alvisi, M. Dahlin, A. Clement, and E. Wong.
Zyzzyva:speculativebyzantinefaulttolerance. InProc.21st
ACM Symposium on Operating Systems Principles (SOSP),
pages45–58,Stevenson,WA,Oct.2007.
[17] T.Kraska,G.Pang,M.J.Franklin,S.Madden,andA.Fekete.
13